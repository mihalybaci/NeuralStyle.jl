{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook uses a convulational neural network to output the input image.\n",
    "The purpose is mostly so that I can better understand CNNs in general, \n",
    "consequently, this \"algorithm\" needs a lot of work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For reference, this code works with Julia v1.4, Flux v0.10.3, and Images v0.22.0. Other versions have not been tested."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Flux\n",
    "using Images\n",
    "using Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - Do the image handling stuff to prepare the data for the CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_in = load(\"../style_images/katsushika-hokusai_the-great-wave-off-kanagawa.jpg\");  # Load the image \n",
    "imgview = Float32.(channelview(image_in));  # Create a view of the image and convert to Float32\n",
    "imgWHC = permutedims(imgview, (3, 2, 1)); # Chane Images CHW order to Flux WHC order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_data = Array{Float32}(undef, (size(imgWHC)[1:2]..., 3, 1));  # Create tensor\n",
    "img_data[:, :, :, 1] = imgWHC;  # Stick image where it belongs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Define helper functions that will ensure that the input image and output images are the same size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pad2d"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "nstrides1d(l, k, p, s)\n",
    "\n",
    "nstrides1d is a function to calculate the number of kernel strides that fit in a given\n",
    "length. This equals the size of a dimension after a convolution.\n",
    "\"\"\"\n",
    "nstrides1d(l, k, p, s) = ((l - k + p) / s + 1)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "nstrides2d(l, k, p, s)\n",
    "\n",
    "nstrides2d is a convenience function that accepts tuple inputs in the manner expected for\n",
    "the pad1d and pad2d functions and outpus 2-element tuple.\n",
    "\"\"\"\n",
    "nstrides2d(l, k, p, s) = (nstrides1d(l[1], k[1], p[1] + p[2], s[1]),\n",
    "                         nstrides1d(l[2], k[2], p[3] + p[4], s[2]))\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "pad1d(l, k, s)\n",
    "\n",
    "Calculate the amount of padding needed to fit an integer number of kernel strides\n",
    "across a given length. While pad_1d works for 2-D inputs, it is suggested to use\n",
    "the helper function pad2d.\n",
    "\n",
    "Inputs:\n",
    "-------\n",
    "l - length\n",
    "k - kernel size\n",
    "s - stride\n",
    "\n",
    "Output:\n",
    "----\n",
    "A 2-element tuple with the number of elements needed to pad each side of a 1-D length.\n",
    "\"\"\"\n",
    "function pad1d(l, k, s)\n",
    "    n = ceil((l - k)/s + 1)  # Number of whole kernels needed to cross l\n",
    "    pad_tot = s*(n - 1) + k - l  # Padding needed to get to n kernels\n",
    "    # If padding still does not give an inter number of kernel strides\n",
    "    # Then print an error\n",
    "    if ((l - k + pad_tot) / s + 1) % 1 != 0\n",
    "        @error \"Could not pad array properly\"\n",
    "    end\n",
    "    # Try to evenly space padding between sides\n",
    "    # left, right, top, and bottom sides.\n",
    "    # The following pads bottom/right sides first\n",
    "    p1 = pad_tot รท 2\n",
    "    p2 = pad_tot - p1\n",
    "\n",
    "    return convert.(Int, (p1, p2))\n",
    "end\n",
    "\n",
    "\"\"\"\n",
    "pad2d(l, k, s)\n",
    "\n",
    "Convience function for pad_1d. This function splats the output into a single,\n",
    "N-element tuple rather than using pad_1d.(x, y, z), which outputs a tuple of tuples\n",
    "\n",
    "Inputs:\n",
    "-------\n",
    "l - length\n",
    "k - kernel size\n",
    "s - stride\n",
    "\n",
    "Output:\n",
    "----\n",
    "A 4-element tuple with the number of elements needed to pad each side of a 2-D matrix.\n",
    "\"\"\"\n",
    "pad2d(l, k, s) = (pad1d(l[1], k[1], s[1])...,  pad1d(l[2], k[2], s[2])...)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - Create the basic 3-layer \"recoder\" (encoder/decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = (3, 3);  # kernel size\n",
    "s = (2, 2);  # stride size\n",
    "d = (1, 1);  # dilation size\n",
    "\n",
    "# Size and padding for the first layer\n",
    "size1 = size(img_data)[1:2];\n",
    "epad1 = pad2d(size1, k, s);\n",
    "# Size and padding for the second layer\n",
    "size2 = nstrides2d(size1, k, epad1, s);\n",
    "epad2 = pad2d(size2, k, s);\n",
    "# Size and padding for the third layer\n",
    "size3 = nstrides2d(size2, k, epad2, s);\n",
    "epad3 = pad2d(size3, k, s);\n",
    "\n",
    "recode = Chain(# Encoder section\n",
    "               Conv(k, 3=>32, relu, pad=epad1, stride=s, dilation=d),\n",
    "               Conv(k, 32=>64, relu, pad=epad2, stride=s, dilation=d),\n",
    "               BatchNorm(64),\n",
    "               Conv(k, 64=>128, relu, pad=epad3, stride=s, dilation=d),\n",
    "               # Decoder section\n",
    "               ConvTranspose(k, 128=>64,relu, pad=epad3, stride=s, dilation=d),\n",
    "               BatchNorm(64),\n",
    "               ConvTranspose(k, 64=>32, relu, pad=epad2, stride=s, dilation=d),\n",
    "               ConvTranspose(k, 32=>3, relu, pad=epad1, stride=s, dilation=d)\n",
    "               );"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - Set up the variables for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "recode_loss (generic function with 1 method)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt = Flux.ADAM()  # Standard optimizer\n",
    "recode_loss(x) = Flux.mse(recode(x), x)  # Compares input image to its CNN version\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - Do the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loop 1 of 1000\n",
      "Training loop 2 of 1000\n",
      "Training loop 3 of 1000\n",
      "Training loop 4 of 1000\n",
      "Training loop 5 of 1000\n",
      "Training loop 6 of 1000\n",
      "Training loop 7 of 1000\n",
      "Training loop 8 of 1000\n",
      "Training loop 9 of 1000\n",
      "Training loop 10 of 1000\n",
      "Training loop 11 of 1000\n",
      "Training loop 12 of 1000\n",
      "Training loop 13 of 1000\n",
      "Training loop 14 of 1000\n",
      "Training loop 15 of 1000\n",
      "Training loop 16 of 1000\n",
      "Training loop 17 of 1000\n",
      "Training loop 18 of 1000\n",
      "Training loop 19 of 1000\n",
      "Training loop 20 of 1000\n",
      "Training loop 21 of 1000\n",
      "Training loop 22 of 1000\n",
      "Training loop 23 of 1000\n",
      "Training loop 24 of 1000\n",
      "Training loop 25 of 1000\n",
      "Training loop 26 of 1000\n",
      "Training loop 27 of 1000\n",
      "Training loop 28 of 1000\n",
      "Training loop 29 of 1000\n",
      "Training loop 30 of 1000\n",
      "Training loop 31 of 1000\n",
      "Training loop 32 of 1000\n",
      "Training loop 33 of 1000\n",
      "Training loop 34 of 1000\n",
      "Training loop 35 of 1000\n",
      "Training loop 36 of 1000\n",
      "Training loop 37 of 1000\n",
      "Training loop 38 of 1000\n",
      "Training loop 39 of 1000\n",
      "Training loop 40 of 1000\n",
      "Training loop 41 of 1000\n",
      "Training loop 42 of 1000\n",
      "Training loop 43 of 1000\n",
      "Training loop 44 of 1000\n",
      "Training loop 45 of 1000\n",
      "Training loop 46 of 1000\n",
      "Training loop 47 of 1000\n",
      "Training loop 48 of 1000\n",
      "Training loop 49 of 1000\n",
      "Training loop 50 of 1000\n",
      "Training loop 51 of 1000\n",
      "Training loop 52 of 1000\n",
      "Training loop 53 of 1000\n",
      "Training loop 54 of 1000\n",
      "Training loop 55 of 1000\n",
      "Training loop 56 of 1000\n",
      "Training loop 57 of 1000\n",
      "Training loop 58 of 1000\n",
      "Training loop 59 of 1000\n",
      "Training loop 60 of 1000\n",
      "Training loop 61 of 1000\n",
      "Training loop 62 of 1000\n",
      "Training loop 63 of 1000\n",
      "Training loop 64 of 1000\n",
      "Training loop 65 of 1000\n",
      "Training loop 66 of 1000\n",
      "Training loop 67 of 1000\n",
      "Training loop 68 of 1000\n",
      "Training loop 69 of 1000\n",
      "Training loop 70 of 1000\n"
     ]
    }
   ],
   "source": [
    "losses = []\n",
    "nepochs = 1000\n",
    "for i=1:nepochs\n",
    "    #println(\"Training loop $i of $nepochs\")\n",
    "    Flux.train!(recode_loss, params(recode), [img_data], opt)\n",
    "    push!(losses, recode_loss(img_data))\n",
    "    #println(\"Total loss = $(losses[end])\");\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - See how the loss performed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = scatter(1:length(losses), losses)  # Make loss plot\n",
    "display(p)  # Display the loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - Put the tensor back into RGB format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_recoded = recode(img_data);  # Create the output tensor\n",
    "outsize = size(im_recoded)[1:2];  # Get the final image dimension\n",
    "output_features = reshape(im_recoded, (outsize..., 3));  # Remove the 4th dimension\n",
    "output_perm = permutedims(output_features, (3, 2, 1)); # Flux WHC order to Images CHW orderr\n",
    "image_out = colorview(RGB, output_perm); # Converts to an RGB image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Great Wave off Kanagawa\n",
    "image_in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# The Not-so-Great Wave off Kanagawa\n",
    "image_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes:\n",
    " - Edge effects are noticeable\n",
    " - Image has pixelation\n",
    " - Colors aren't quite right"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: (in order)\n",
    " - Test more features and more layers"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.4.0",
   "language": "julia",
   "name": "julia-1.4"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
